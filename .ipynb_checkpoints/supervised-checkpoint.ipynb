{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage import exposure\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "n_classes = 10\n",
    "#dimension of z or latent representation\n",
    "z_dimension = 2\n",
    "#dimension of X or data\n",
    "X_dimension = 784\n",
    "#dimension of label of data\n",
    "y_dimension = 10\n",
    "\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "VALID_BATCH_SIZE = 10000\n",
    "EPOCHS = 500\n",
    "N = 1000\n",
    "TINY_ERROR = 1e-15\n",
    "DATA_PATH = \"/floyd/input/skripsi_datasets_2/\"\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "training_reconstruction_loss = []\n",
    "training_generator_loss = []\n",
    "training_discriminator_loss = []\n",
    "training_generator_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../../home/Data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(28), transforms.ToTensor()]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../../home/Data/mnist\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(28), transforms.ToTensor()]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "class Convolutional_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Convolutional_Net, self).__init__()\n",
    "        self.convolutional1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.convolutional2 = nn.Conv2d(20, 50, 5 , 1)\n",
    "        self.linear1 = nn.Linear(4*4*50, 500)\n",
    "        self.linear2 = nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.convolutional1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.convolutional2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    classifier = Convolutional_Net()\n",
    "    classifier.load_state_dict(torch.load(\"fashionmnist.pt\"))\n",
    "    classifier.cuda(cuda)\n",
    "    classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_dimension, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, z_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Decoder\n",
    "class Decoder_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(z_dimension + n_classes, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, X_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        s = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "class Discriminator_net_gauss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_net_gauss, self).__init__()\n",
    "        self.layer1 = nn.Linear(z_dimension, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(decoder, encoder, discriminator_gauss, decoder_optimizer, encoder_optimizer, generator_optimizer, discriminator_optimizer, data_loader):\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    discriminator_gauss.train()\n",
    "\n",
    "    for X, target in data_loader:\n",
    "        X = X * 0.3081 + 0.1307\n",
    "        X.resize_(TRAIN_BATCH_SIZE, X_dimension)\n",
    "        X, target = Variable(X), Variable(target)\n",
    "        if cuda:\n",
    "            X, target = X.cuda(cuda), target.cuda(cuda)\n",
    "\n",
    "        # Init gradients\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "\n",
    "\n",
    "        z_gauss = encoder(X)\n",
    "        \n",
    "        category = np.array(target.data.tolist())\n",
    "        category = np.eye(n_classes)[category].astype('float32')\n",
    "        category = torch.from_numpy(category)\n",
    "        z_category = Variable(category)\n",
    "        \n",
    "        if cuda:\n",
    "            z_category = z_category.cuda(cuda)\n",
    "\n",
    "        z_sample = torch.cat((z_category, z_gauss), 1)\n",
    "\n",
    "        X_sample = decoder(z_sample)\n",
    "        compared_with_original = X.resize(TRAIN_BATCH_SIZE, X_dimension)\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "        reconstruction_loss = mse_loss(X_sample + TINY_ERROR, compared_with_original + TINY_ERROR)\n",
    "        \n",
    "        reconstruction_loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "\n",
    "        # Discriminator\n",
    "        encoder.eval()\n",
    "        z_real_gauss = Variable(torch.randn(TRAIN_BATCH_SIZE, z_dimension) * 5.)\n",
    "        if cuda:\n",
    "            z_real_gauss = z_real_gauss.cuda(cuda)\n",
    "\n",
    "        z_fake_gauss = encoder(X)\n",
    "\n",
    "        discriminator_real_gauss = discriminator_gauss(z_real_gauss)\n",
    "        discriminator_fake_gauss = discriminator_gauss(z_fake_gauss)\n",
    "\n",
    "        discriminator_loss = 0.5 * (torch.mean((discriminator_real_gauss + TINY_ERROR - 1)**2) + torch.mean((discriminator_fake_gauss + TINY_ERROR)**2))\n",
    "\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "\n",
    "        # Generator\n",
    "        encoder = encoder.train()\n",
    "        z_fake_gauss = encoder(X)\n",
    "\n",
    "        generator_fake_gauss = discriminator_gauss(z_fake_gauss)\n",
    "        generator_loss = 0.5 * torch.mean((generator_fake_gauss + TINY_ERROR - 1)**2)\n",
    "\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "\n",
    "    return discriminator_loss, generator_loss, reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"Kaos\",\n",
    "                 1: \"Cln Pnjg\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Gaun\",\n",
    "                 4: \"Mantel\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Kemeja\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Tas\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]\n",
    "\n",
    "def train_model(train_loader, valid_loader):\n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    if cuda:\n",
    "        encoder = Encoder_net().cuda(cuda)\n",
    "        decoder = Decoder_net().cuda(cuda)\n",
    "        discriminator_gauss = Discriminator_net_gauss().cuda(cuda)\n",
    "    else:\n",
    "        encoder = Encoder_net()\n",
    "        decoder = Decoder_net()\n",
    "        discriminator_gauss = Discriminator_net_gauss()\n",
    "\n",
    "    #learning rates for optimization\n",
    "    learning_rate_1 = 0.0002\n",
    "    learning_rate_2 = 0.00005\n",
    "\n",
    "    #optimization for decoder and encoder\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate_1)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate_1)\n",
    "\n",
    "    generator_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate_1)\n",
    "    discriminator_optimizer = optim.Adam(discriminator_gauss.parameters(), lr=learning_rate_1)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        discriminator_loss, generator_loss, reconstruction_loss = train_one_epoch(decoder, encoder, discriminator_gauss, \n",
    "                                                                              decoder_optimizer, encoder_optimizer, generator_optimizer, \n",
    "                                                                              discriminator_optimizer, train_loader)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        if epoch % 10 == 0:\n",
    "            training_reconstruction_loss.append(reconstruction_loss)\n",
    "            training_generator_loss.append(generator_loss)\n",
    "            training_discriminator_loss.append(discriminator_loss)\n",
    "            print('Epoch-{}, Time-{:.2}, Discriminator_loss-{:.4}, Generator_loss-{:.4}, reconstruction_loss-{:.4}'.format(epoch, epoch_time, discriminator_loss.item(), generator_loss.item(), reconstruction_loss.item()))\n",
    "    \n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            with torch.no_grad():\n",
    "                encoder = encoder.eval()\n",
    "                decoder = decoder.eval()\n",
    "                discriminator_gauss = discriminator_gauss.eval()\n",
    "\n",
    "                X_test = None\n",
    "                y_test = None\n",
    "\n",
    "                for X, target in valid_loader:\n",
    "                    X_test = X\n",
    "                    y_test = target\n",
    "                    break\n",
    "\n",
    "                if is_cuda:\n",
    "                    X_test = X_test.cuda(cuda)\n",
    "\n",
    "                X_test = X_test.resize(VALID_BATCH_SIZE, X_dimension) \n",
    "\n",
    "                list_y_test = []\n",
    "                for item in y_test:\n",
    "                    list_y_test.append(item.item())\n",
    "\n",
    "\n",
    "                encoded_X_test = encoder(X_test)\n",
    "                training_generator_sample.append(encoded_X_test)\n",
    "                target_list = list_y_test\n",
    "\n",
    "                '''\n",
    "                figure = plt.figure()\n",
    "                set_classes = set(target_list)\n",
    "                color_map = plt.cm.rainbow(np.linspace(0, 1, len(set_classes)))\n",
    "                axis = plt.subplot(111, aspect='equal')\n",
    "                box = axis.get_position()\n",
    "                axis.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "                handles = [mpatches.Circle((0, 0), label=class_, color=color_map[i]) for i, class_ in enumerate(set_classes)]\n",
    "                axis.legend(handles=handles, shadow=True, bbox_to_anchor=(1.05, 0.45), fancybox=True, loc='center left')\n",
    "                kwargs = {'alpha': 0.8, 'c': [color_map[i] for i in target_list]}\n",
    "                encoded_X_test_cpu = encoded_X_test.cpu()\n",
    "                plt.scatter(encoded_X_test_cpu[:, 0].detach().numpy(), encoded_X_test_cpu[:, 1].detach().numpy(), s = 2, **kwargs)\n",
    "                axis.set_xlim([-20, 20])\n",
    "                axis.set_ylim([-20, 20])\n",
    "\n",
    "                plt.savefig('2_latent_space_supervised_aae_least/epoch_%d.png' % epoch)\n",
    "                plt.close('all')\n",
    "                '''\n",
    "\n",
    "                n_digits = 20\n",
    "                #decoded_X_test = decoder(encoder(X_test[:n_digits]))\n",
    "\n",
    "                category_test = np.array(y_test.numpy().data.tolist())\n",
    "                category_test = np.eye(n_classes)[category_test].astype('float32')\n",
    "                category_test = torch.from_numpy(category_test)\n",
    "                z_category_test = Variable(category_test[:n_digits])\n",
    "                encoded_X_test = encoder(X_test[:n_digits])\n",
    "\n",
    "                if is_cuda:\n",
    "                    z_category_test = z_category_test.cuda(cuda)\n",
    "\n",
    "                encoded_X_test = torch.cat((z_category_test, encoded_X_test), 1)\n",
    "                decoded_X_test = decoder(encoded_X_test)\n",
    "\n",
    "                resized_decoded_X_test = decoded_X_test.resize(n_digits, 1, 28, 28)\n",
    "                resized_decoded_X_test = resized_decoded_X_test.cuda(cuda)\n",
    "                label_decoded = classifier(resized_decoded_X_test)\n",
    "                label_decoded = label_decoded.argmax(dim=1, keepdim=True)\n",
    "                label_decoded = torch.flatten(label_decoded)\n",
    "\n",
    "                original_X = X_test[:n_digits]\n",
    "                resized_original_X = original_X.resize(n_digits, 1, 28, 28)\n",
    "                resized_original_X = resized_original_X.cuda(cuda)\n",
    "                target_original_X = classifier(resized_original_X)\n",
    "                target_original_X = target_original_X.argmax(dim=1, keepdim=True)\n",
    "                target_original_X = torch.flatten(target_original_X)\n",
    "\n",
    "                decoded_label_cpu = label_decoded.cpu().detach().numpy()\n",
    "                decoded_target_original_X = target_original_X.cpu().detach().numpy()\n",
    "                decoded_X_test_cpu = decoded_X_test.cpu()\n",
    "                decoded_X_test_cpu = np.reshape(decoded_X_test_cpu.detach().numpy(), [-1, 28, 28]) * 255\n",
    "                figure = plt.figure(figsize=(20, 4))\n",
    "\n",
    "                for i in range (n_digits):\n",
    "                    axis = plt.subplot(2, n_digits, i + 1)\n",
    "                    axis.set_title(output_label(decoded_target_original_X[i]))\n",
    "                    X_test_cpu = X_test.cpu()\n",
    "                    plt.imshow(X_test_cpu[i].reshape(28, 28).detach().numpy())\n",
    "                    plt.gray()\n",
    "                    axis.get_xaxis().set_visible(False)\n",
    "                    axis.get_yaxis().set_visible(False)\n",
    "\n",
    "                    axis = plt.subplot(2, n_digits, i + 1 + n_digits)\n",
    "                    axis.set_title(output_label(decoded_label_cpu[i]))\n",
    "                    plt.imshow(decoded_X_test_cpu[i])\n",
    "                    plt.gray()\n",
    "                    axis.get_xaxis().set_visible(False)\n",
    "                    axis.get_yaxis().set_visible(False)\n",
    "\n",
    "                plt.savefig('3_reconstruction_supervised_aae_least/recon_%d.png' % y)\n",
    "                plt.close('all')\n",
    "                \n",
    "                \n",
    "                z = torch.randn(20, 2) * 5\n",
    "                z = z.float().cuda(cuda)\n",
    "\n",
    "                target = torch.randint(10, (20, 1))\n",
    "                target = target.flatten()\n",
    "\n",
    "                one_hot_target = torch.zeros(20, 10)\n",
    "                one_hot_target[torch.arange(20), target] = 1\n",
    "                one_hot_target = one_hot_target.cuda(cuda)\n",
    "\n",
    "                z_target = torch.cat([one_hot_target, z], dim=1)\n",
    "                z_target = z_target.cuda(cuda)\n",
    "\n",
    "                recon_z = decoder(z_target)\n",
    "                recon_z = recon_z.resize(20, 1, 28, 28)\n",
    "                \n",
    "                recon = recon_z.cpu()\n",
    "                recon = np.reshape(recon.detach().numpy(), [-1, 28, 28]) * 255\n",
    "                \n",
    "                figure = plt.figure(figsize=(20, 4))\n",
    "\n",
    "                for i in range (20):\n",
    "                    axis = plt.subplot(2, n_digits, i + 1)\n",
    "                    plt.imshow(recon[i].reshape(28, 28))\n",
    "                    plt.gray()\n",
    "                    axis.get_xaxis().set_visible(False)\n",
    "                    axis.get_yaxis().set_visible(False)\n",
    "                \n",
    "                plt.savefig('3_sampling_supervised_aae_least/epoch_%d.png' % epoch)\n",
    "                plt.close()\n",
    "                \n",
    "\n",
    "                '''\n",
    "                z_sampling = [np.linspace(-5, 5, 10) for i in range (10)]\n",
    "\n",
    "                n_x, n_y = 10, 10\n",
    "                random_input = np.random.randn(10, z_dimension)\n",
    "                sample_y = np.identity(10)\n",
    "                plt.subplot()\n",
    "                grid_spec = gridspec.GridSpec(n_x, n_y, hspace=0.05, wspace=0.05)\n",
    "                i = 0\n",
    "                for r in random_input:\n",
    "                    for t in sample_y:\n",
    "                        r = np.reshape(r, (1, z_dimension))\n",
    "                        t = np.reshape(t, (1, n_classes))\n",
    "                        input_decoder = np.concatenate((t, r), 1)\n",
    "                        input_decoder = input_decoder.astype('float32')\n",
    "                        input_decoder = torch.from_numpy(input_decoder).float()\n",
    "                        input_decoder = input_decoder.cuda(cuda)\n",
    "\n",
    "                        decoded_X = decoder(input_decoder)\n",
    "                        decoded_X_cpu = decoded_X.cpu().detach().numpy()\n",
    "\n",
    "                        axis = plt.subplot(grid_spec[i])\n",
    "                        i += 1\n",
    "                        image = np.array(decoded_X_cpu.tolist()).reshape(28, 28)\n",
    "                        axis.imshow(image, cmap='gray')\n",
    "                        axis.set_xticks([])\n",
    "                        axis.set_yticks([])\n",
    "                        axis.set_aspect('auto')\n",
    "\n",
    "                plt.savefig('3_sampling_supervised_aae_least/epoch_%d.png' % epoch)\n",
    "                plt.close()\n",
    "                '''\n",
    "                \n",
    "                encoder = encoder.train()\n",
    "                decoder = decoder.train()\n",
    "                discriminator_gauss = discriminator_gauss.train()\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labeled_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-38ff71bcc3e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_unlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labeled_loader' is not defined"
     ]
    }
   ],
   "source": [
    "trained_encoder, trained_decoder = train_model(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location_encoder = \"3cnn-least-standard-encoder.pt\"\n",
    "file_location_decoder = \"3cnn-least-standard-decoder.pt\"\n",
    "file_location_discriminator = \"3cnn-least-standard-discriminator.pt\"\n",
    "torch.save(trained_encoder.state_dict(), file_location_encoder)\n",
    "torch.save(trained_decoder.state_dict(), file_location_decoder)\n",
    "torch.save(trained_discriminator.state_dict(), file_location_discriminator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
